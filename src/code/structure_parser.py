"""
code.src.structure_parser çš„ Docstring
æœ¬è„šæœ¬ç”¨äºæå–Wordæ ‡é¢˜é¢„è®¡å¯¹åº”é¡µç èŒƒå›´çš„ç»“æ„åŒ–ä¿¡æ¯
"""
import fitz  # PyMuPDF
from docx import Document
from loguru import logger
from typing import List, Dict, Any
import os

from pathlib import Path
#å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•
HERE = Path(__file__).resolve().parent
#é¡¹ç›®æ ¹ç›®å½•
ROOT = HERE.parent.parent

#é…ç½®æ—¥å¿—åˆ°æ§åˆ¶å°
logger = logger.bind(module="structure_parser")

# å¯¼å…¥æ ‡é¢˜æå–å™¨
from .title_extractor import TitleExtractor

def parse_structure(doc_path: str = f"{ROOT}/ç¤ºä¾‹æ•°æ®/test.docx", pdf_path: str= f"{ROOT}/ç¤ºä¾‹æ•°æ®/test.pdf") -> List[Dict[str, Any]]:
    """
    è§£æWordæ–‡æ¡£çš„ç»“æ„ä¿¡æ¯
    Args:
        doc_path (str): Wordæ–‡æ¡£çš„è·¯å¾„
        pdf_path (str): å¯¹åº”çš„PDFæ–‡æ¡£è·¯å¾„
    Returns:
        List[Dict[str, Any]]: åŒ…å«æ ‡é¢˜åŠå…¶é¡µç èŒƒå›´çš„ç»“æ„
        ç¤ºä¾‹ï¼š
        [
            {
                "title": "ç¬¬ä¸€ç«  ç»ªè®º",
                "start_page": 1,
                "end_page": 5
            },
            {
                "title": "ç¬¬äºŒç«  æ–‡çŒ®ç»¼è¿°",
                "start_page": 6,
                "end_page": 15
            }
        ]
    """
    #æ£€æŸ¥ä¼ å…¥å‚æ•°æ˜¯å¦å®Œæ•´if not doc_path or not pdf_path:
    try:
        if not doc_path or not pdf_path:
            logger.error("å¿…é¡»æä¾› Word æ–‡æ¡£è·¯å¾„å’Œå¯¹åº”çš„ PDF è·¯å¾„")
            return []
    except Exception as e:
        logger.error(f"æ£€æŸ¥è·¯å¾„å‚æ•°æ—¶å‡ºé”™: {e}")
        return []

    # åˆå§‹åŒ–ç»“æ„ä¿¡æ¯åˆ—è¡¨
    structure_info = []

    if not os.path.exists(doc_path):
        logger.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {doc_path}")
        return structure_info
    # è¯»å–Wordæ–‡æ¡£
    try:
        doc = Document(doc_path)
    except Exception as e:
        logger.error(f"è¯»å–Wordæ–‡æ¡£æ—¶å‡ºé”™: {e}")
        return structure_info

    # æå–æ ‡é¢˜ä¿¡æ¯
    headings = extract_headings(doc)
    if not headings:
        logger.warning("æœªåœ¨æ–‡æ¡£ä¸­æ£€æµ‹åˆ°æ ‡é¢˜æ ·å¼çš„æ®µè½")
        return structure_info
    
    # å°†Wordè½¬æ¢ä¸ºPDFä»¥è·å–é¡µç ä¿¡æ¯ï¼ˆæˆ–è€…é€šè¿‡å·²æœ‰çš„PDFæ–‡ä»¶ï¼‰
    pdf_doc = fitz.open(pdf_path)
    # æœç´¢æ¸¸æ ‡ï¼Œè®°å½•ä¸Šä¸€ä¸ªæ ‡é¢˜æ‰€åœ¨çš„é¡µç 
    current_cursor = 0
    # å­˜å‚¨æ ‡é¢˜åŠå…¶èµ·å§‹é¡µç 
    heading_pages = []

    for heading in headings:
            # 1. ä»æ¸¸æ ‡ä½ç½®å¼€å§‹å¾€åæœ
            found_page = get_page_number_for_heading(pdf_doc, heading, start_page=current_cursor)
            
            # 2. å¦‚æœæ²¡æ‰¾åˆ°ï¼ˆå¯èƒ½æ˜¯ Word æ’ç‰ˆå¯¼è‡´çš„æ¢è¡Œé—®é¢˜ï¼‰ï¼Œå°è¯•æ¨¡ç³Šæœç´¢
            if found_page == -1 and len(heading) > 10:
                 # åªæœå‰ 15 ä¸ªå­—
                short_text = heading[:15]
                found_page = get_page_number_for_heading(pdf_doc, short_text, start_page=current_cursor)

            if found_page != -1:
                logger.info(f"  ğŸ“ [P.{found_page}] {heading}")
                heading_pages.append((heading, found_page))
                # ã€å…³é”®ã€‘æ›´æ–°æ¸¸æ ‡ï¼šä¸‹ä¸€ä¸ªæ ‡é¢˜ä¸å¯èƒ½å‡ºç°åœ¨å½“å‰æ ‡é¢˜ä¹‹å‰
                # æ‰€ä»¥ä¸‹æ¬¡æœç´¢ç›´æ¥ä»å½“å‰é¡µå¼€å§‹
                current_cursor = found_page
            else:
                logger.warning(f"  âŒ [æœªæ‰¾åˆ°] {heading}")
                # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œæ¸¸æ ‡ä¸æ›´æ–°ï¼Œä¿æŒåœ¨åŸåœ°ï¼Œç»§ç»­æ‰¾ä¸‹ä¸€ä¸ªæ ‡é¢˜

    for idx, (heading, start_page) in enumerate(heading_pages):
        # ä¸‹ä¸€ä¸ªæ ‡é¢˜çš„é¡µç ç”¨äºæ¨æ–­å½“å‰æ ‡é¢˜çš„ç»“æŸé¡µï¼Œè‡³å°‘ä¸å°äºå½“å‰èµ·å§‹é¡µ
        if idx + 1 < len(heading_pages):
            next_start = heading_pages[idx + 1][1]
            end_page = max(start_page, next_start - 1)
        else:
            end_page = start_page  # æœ€åä¸€ä¸ªæ ‡é¢˜æš‚ä¸”è®¤ä¸ºè¦†ç›–åˆ°æ–‡ä»¶ç»“æŸ

        structure_info.append(
            {
                "title": heading,
                "start_page": start_page,
                "end_page": end_page
            }
        )

    return structure_info

def extract_headings(doc: Document, min_score: float = 60.0) -> List[str]:
    """æå–Wordæ–‡æ¡£ä¸­çš„æ ‡é¢˜æ–‡æœ¬ã€‚
    
    åŸºäºå¤šç‰¹å¾è¯„åˆ†ç³»ç»Ÿæ™ºèƒ½è¯†åˆ«æ ‡é¢˜ï¼Œä¸ä¾èµ–æ ·å¼åç§°ã€‚
    ä½¿ç”¨TitleExtractorå®ç°ï¼Œæ”¯æŒå¤šçº§æ ‡é¢˜è¯†åˆ«å’Œå¯é…ç½®çš„è¯„åˆ†é˜ˆå€¼ã€‚
    
    Args:
        doc: Wordæ–‡æ¡£å¯¹è±¡
        min_score: æ ‡é¢˜æœ€ä½è¯„åˆ†é˜ˆå€¼ï¼Œé»˜è®¤60.0åˆ†
        
    Returns:
        List[str]: æå–çš„æ ‡é¢˜æ–‡æœ¬åˆ—è¡¨
    """
    # åˆå§‹åŒ–æ ‡é¢˜æå–å™¨
    extractor = TitleExtractor()
    
    # æå–æ ‡é¢˜ï¼Œä½¿ç”¨æŒ‡å®šçš„è¯„åˆ†é˜ˆå€¼
    titles = extractor.extract(doc, min_score=min_score)
    
    # æå–æ ‡é¢˜æ–‡æœ¬ï¼Œä¿æŒä¸åŸæœ‰å‡½æ•°æ¥å£å…¼å®¹
    headings = [title['text'] for title in titles]
    
    logger.info(f"ä½¿ç”¨è¯„åˆ†ç³»ç»Ÿæå–åˆ° {len(headings)} ä¸ªæ ‡é¢˜ï¼ˆé˜ˆå€¼: {min_score}ï¼‰")
    
    # ç»Ÿè®¡å„çº§æ ‡é¢˜æ•°é‡
    level_counts = {}
    for title in titles:
        level = title['level']
        level_counts[level] = level_counts.get(level, 0) + 1
    
    if level_counts:
        logger.debug(f"æ ‡é¢˜çº§åˆ«åˆ†å¸ƒ: {level_counts}")
    
    return headings

    """
    è·å–æ ‡é¢˜æ‰€åœ¨çš„é¡µç 
    Args:
        heading (str): æ ‡é¢˜æ–‡æœ¬
    Returns:
        int: æ ‡é¢˜æ‰€åœ¨çš„é¡µç 
    """
    # è¿™é‡Œéœ€è¦å®ç°å…·ä½“çš„é€»è¾‘æ¥è·å–æ ‡é¢˜æ‰€åœ¨é¡µç 
    # å¯èƒ½éœ€è¦ç»“åˆPDFè§£æåº“å¦‚PyMuPDFæ¥å®ç°
    return 1  # ç¤ºä¾‹è¿”å›ç¬¬ä¸€é¡µ

def get_page_number_for_heading(pdf_doc: fitz.Document, target_text: str, start_page: int = 0) -> int:
        """
        è½»é‡åŒ–æœç´¢ï¼šåªä» start_page å¼€å§‹å¾€åæ‰¾
        """
        clean_text = target_text.strip()
        if not clean_text:
            return -1

        total_pages = len(pdf_doc)
        
        # ä» start_page å¼€å§‹ï¼Œç›´åˆ°æ–‡æ¡£ç»“æŸ
        for i in range(start_page, total_pages):
            page = pdf_doc[i]
            # hit_max=1: åªè¦æ‰¾åˆ°ä¸€å¤„å°±ç«‹é©¬è¿”å›ï¼Œä¸å†æ‰«ææ•´é¡µå…¶ä»–ä½ç½®
            if page.search_for(clean_text):
                return i
        
        return -1


def main():
    docs_path = ROOT/"ç¤ºä¾‹æ•°æ®/test.docx"
    pdf_path = ROOT/"ç¤ºä¾‹æ•°æ®/test.pdf"
    structure = parse_structure(docs_path, pdf_path)
    for item in structure:
        logger.info(f"æ ‡é¢˜: {item['title']}, èµ·å§‹é¡µ: {item['start_page']}, ç»“æŸé¡µ: {item['end_page']}")

if __name__ == "__main__":
    main()